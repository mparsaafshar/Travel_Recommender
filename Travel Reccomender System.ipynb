{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756eb356-3ac3-4245-9439-ba6c978dfbfc",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207ee00-2946-41c8-9053-c2077f7fa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a420fb-a66e-47c0-ac39-3e4858b5a015",
   "metadata": {},
   "source": [
    "Make a simple artificial dataset of users reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce35099-4feb-4c59-9761-b28f9db208eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [f\"user_{i}\" for i in range(1, 31)]\n",
    "cities = [\n",
    "    \"Tehran\", \"Mashhad\", \"Isfahan\", \"Shiraz\", \"Tabriz\", \"Kerman\", \"Kish\", \"Qeshm\", \"Rasht\",\n",
    "    \"Ahvaz\", \"Yazd\", \"Urmia\", \"Kermanshah\", \"Sari\", \"Gorgan\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for user in users:\n",
    "    destinations = random.sample(cities, 3)  \n",
    "    for i, city in enumerate(destinations):\n",
    "        rating = round(min(max(random.normalvariate(4, 0.5), 1), 5))  \n",
    "        \n",
    "        start_date = pd.Timestamp.now() - pd.Timedelta(days=random.randint(1, 365))\n",
    "        end_date = start_date + pd.Timedelta(days=random.randint(2, 7))  \n",
    "        \n",
    "        data.append({\n",
    "            \"user_id\": user,\n",
    "            \"destination\": city,\n",
    "            \"rating\": rating,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date\n",
    "        })\n",
    "\n",
    "df_reviews = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bacb4-48f9-4917-abf7-3cc1cf2cbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104e1a7-8f0b-4018-813b-a60984021fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['start_date'] = pd.to_datetime(df_reviews['start_date'])\n",
    "df_reviews['end_date'] = pd.to_datetime(df_reviews['end_date'])\n",
    "\n",
    "df_reviews['start_month'] = df_reviews['start_date'].dt.month\n",
    "df_reviews['end_month'] = df_reviews['end_date'].dt.month\n",
    "\n",
    "df_reviews['month'] = df_reviews.apply(\n",
    "    lambda row: (row['start_month'] + row['end_month']) / 2 if row['start_month'] != row['end_month'] \n",
    "    else row['start_month'], axis=1)\n",
    "\n",
    "print(df_reviews[['user_id', 'destination', 'start_date', 'end_date', 'month']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0d34c-4aee-4660-b633-313b02ac22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = #r\"User Reviews Dataset Path\"\n",
    "df_reviews.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b82b9-c960-424e-be53-336f9f108e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersdata = df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4405393f-c12b-4bb7-b495-4759cdd9340a",
   "metadata": {},
   "source": [
    "Cities weather informations daataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b22fd2-b32a-4244-9d1d-cb8c11e05e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENWEATHER_API_KEY = #\"API KEY\"\n",
    "\n",
    "cities = [\n",
    "    \"Tehran\", \"Mashhad\", \"Isfahan\", \"Shiraz\", \"Tabriz\", \"Kerman\", \"Kish\", \"Qeshm\", \"Rasht\",\n",
    "    \"Ahvaz\", \"Yazd\", \"Urmia\", \"Kermanshah\", \"Sari\", \"Gorgan\"\n",
    "]\n",
    "\n",
    "def get_weather_data(city):\n",
    "    try:\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return {\n",
    "                \"city\": city,\n",
    "                \"temperature\": data[\"main\"][\"temp\"],\n",
    "                \"feels_like\": data[\"main\"][\"feels_like\"],\n",
    "                \"cloudiness\": data[\"clouds\"][\"all\"],\n",
    "                \"humidity\": data[\"main\"][\"humidity\"],\n",
    "                \"rain\": data.get(\"rain\", {}).get(\"1h\", 0),  \n",
    "                \"snow\": data.get(\"snow\", {}).get(\"1h\", 0),  \n",
    "                \"timestamp\": datetime.now()\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Weather API Error for {city}: {response.status_code}\")\n",
    "            return {\"city\": city, \"temperature\": None, \"feels_like\": None, \"cloudiness\": None,\n",
    "                    \"humidity\": None, \"rain\": None, \"snow\": None, \"timestamp\": datetime.now()}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data for {city}: {e}\")\n",
    "        return {\"city\": city, \"temperature\": None, \"feels_like\": None, \"cloudiness\": None,\n",
    "                \"humidity\": None, \"rain\": None, \"snow\": None, \"timestamp\": datetime.now()}\n",
    "\n",
    "real_time_weather_data = []\n",
    "for city in cities:\n",
    "    print(f\"Fetching weather data for {city}...\")\n",
    "    weather = get_weather_data(city)\n",
    "    real_time_weather_data.append(weather)\n",
    "\n",
    "df_weather = pd.DataFrame(real_time_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002d4fc-71ec-48d0-8c1e-73fbcfd4cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5facb3e-57e8-4c20-b5d2-4d332858ea95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
    "\n",
    "df_weather['month'] = df_weather['timestamp'].dt.month\n",
    "\n",
    "print(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783f9a1-ea8b-4a5b-90c9-08ee31b54263",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = #r\"Cities weather dataset Path\"\n",
    "df_weather.to_excel(file_path2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8d38a-d472-47fa-a9ad-db154b77e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamicdata = df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2dfd33-e9a4-47b8-bec5-1c5b228433b6",
   "metadata": {},
   "source": [
    "Cities static inforemation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4dde64-2e62-4233-8d49-c23a68c5c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENWEATHER_API_KEY = #\"API KEY\"\n",
    "\n",
    "cities = [\n",
    "    \"Tehran\", \"Mashhad\", \"Isfahan\", \"Shiraz\", \"Tabriz\", \"Kerman\", \"Kish\", \"Qeshm\", \"Rasht\",\n",
    "    \"Ahvaz\", \"Yazd\", \"Urmia\", \"Kermanshah\", \"Sari\", \"Gorgan\"\n",
    "]\n",
    "\n",
    "def get_city_coordinates(city_name, api_key):\n",
    "\n",
    "    base_url = \"http://api.openweathermap.org/geo/1.0/direct\"\n",
    "    params = {\"q\": city_name, \"limit\": 1, \"appid\": api_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"lat\"], data[0][\"lon\"]\n",
    "    return None, None\n",
    "\n",
    "def get_elevation(lat, lon, api_key):\n",
    "\n",
    "    base_url = f\"https://api.openweathermap.org/data/2.5/elevation\"\n",
    "    params = {\"lat\": lat, \"lon\": lon, \"appid\": api_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"elevation\" in data:\n",
    "            return data[\"elevation\"]\n",
    "    return None\n",
    "\n",
    "results = []\n",
    "for city in cities:\n",
    "    print(f\"Processing city: {city}...\")\n",
    "    lat, lon = get_city_coordinates(city, OPENWEATHER_API_KEY)\n",
    "    if lat and lon:\n",
    "        elevation = get_elevation(lat, lon, OPENWEATHER_API_KEY)\n",
    "        results.append({\n",
    "            \"City\": city,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"Elevation\": elevation\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {city}.\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "output_path = \"cities_weather_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a7748-1b61-48ea-a006-4f8d7cbad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "staticdata = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25886d4b-b696-425d-9a04-cbff9c0b6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path2 = #r\"Staticdata dataset Path\"\n",
    "staticdata.to_excel(file_path2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bfbfe-1143-4f21-941b-9a74b587caab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usersdata = pd.read_excel('''r\"User Reviews Dataset Path\"''')\n",
    "print(usersdata)\n",
    "dynamicdata = pd.read_excel('''r\"Cities weather dataset Path\"''')\n",
    "print(dynamicdata)\n",
    "staticdata = pd.read_excel('''r\"Staticdata dataset Path\"''')\n",
    "print(staticdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bbbcb-1054-4485-a96d-c0d35d707fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dynamicdata_hierachyc = dynamicdata\n",
    "\n",
    "features = [\"temperature\", \"feels_like\", \"cloudiness\", \"humidity\", \"rain\", \"snow\"]\n",
    "X = dynamicdata_hierachyc[features]\n",
    "\n",
    "linkage_matrix = linkage(X, method=\"ward\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(linkage_matrix, labels=dynamicdata_hierachyc[\"city\"].values, leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Cities\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "\n",
    "n_clusters = 4\n",
    "clusters = fcluster(linkage_matrix, n_clusters, criterion=\"maxclust\")\n",
    "dynamicdata_hierachyc[\"cluster\"] = clusters\n",
    "\n",
    "print(dynamicdata_hierachyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0a312-5063-481e-9392-e9647dd5dc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = [\"temperature\", \"feels_like\", \"cloudiness\", \"humidity\", \"rain\", \"snow\"]\n",
    "X = dynamicdata_hierachyc[features]\n",
    "scaler = StandardScaler()\n",
    "dynamicdata_scaled = scaler.fit_transform(X)\n",
    "\n",
    "cluster_range = range(2, 10)  \n",
    "m_values = [1.5, 2, 2.5, 3]  \n",
    "\n",
    "results = []\n",
    "\n",
    "for n_clusters in cluster_range:\n",
    "    for m in m_values:\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "            dynamicdata_scaled.T,\n",
    "            n_clusters,\n",
    "            m,\n",
    "            error=0.005,\n",
    "            maxiter=1000,\n",
    "            init=None\n",
    "        )\n",
    "\n",
    "        min_distance = np.min(\n",
    "            [np.linalg.norm(cntr[i] - cntr[j]) for i in range(n_clusters) for j in range(i + 1, n_clusters)]\n",
    "        )\n",
    "        xb = np.sum(np.min(d, axis=0)) / (len(X) * min_distance**2)\n",
    "\n",
    "        results.append({\n",
    "            'n_clusters': n_clusters,\n",
    "            'm': m,\n",
    "            'Xie-Beni': xb\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_xb = results_df.loc[results_df['Xie-Beni'].idxmin()]\n",
    "\n",
    "print(\"Best setting by Xie-Beni:\")\n",
    "print(best_xb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for m in m_values:\n",
    "    plt.plot(results_df[results_df['m'] == m]['n_clusters'],\n",
    "             results_df[results_df['m'] == m]['Xie-Beni'], label=f'm={m}')\n",
    "plt.title(\"Xie-Beni vs Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Xie-Beni Index\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a16ac-8418-4e6f-9247-1e6227ed21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"temperature\", \"feels_like\", \"cloudiness\", \"humidity\", \"rain\", \"snow\"]\n",
    "X = dynamicdata_hierachyc[features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dynamicdata2 = dynamicdata.copy()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters = 3\n",
    "\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    X_scaled.T,  \n",
    "    n_clusters,     \n",
    "    1.5,              \n",
    "    error=0.005,    \n",
    "    maxiter=1000,   \n",
    "    init=None       \n",
    ")\n",
    "\n",
    "cluster_membership = np.argmax(u, axis=0)\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    dynamicdata2[f'cluster_{i}_membership'] = u[i, :]\n",
    "\n",
    "dynamicdata2['cluster'] = cluster_membership\n",
    "\n",
    "print(\"Fuzzy scores and Clusters\")\n",
    "print(dynamicdata2.head())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_clusters):\n",
    "    plt.scatter(X_scaled[cluster_membership == i, 0],\n",
    "                X_scaled[cluster_membership == i, 1],\n",
    "                label=f'Cluster {i}')\n",
    "plt.scatter(cntr[:, 0], cntr[:, 1], s=300, c='red', marker='X', label='Centers')\n",
    "plt.title('Fuzzy C-Means Clustering')\n",
    "plt.xlabel('Feature 1 (e.g., temperature)')\n",
    "plt.ylabel('Feature 2 (e.g., feels_like)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ddf35-ef13-405d-82a6-04c6283d1a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dynamicdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604ef95-c0e0-4d49-b19a-44ec51a2df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersdata2 = usersdata2.drop(columns=['start_date', 'end_date', 'timestamp', 'start_month', 'end_month', 'month'])\n",
    "\n",
    "users_grouped = usersdata2.groupby('user_id').apply(lambda x: x.sort_values('destination')).reset_index(drop=True)\n",
    "\n",
    "users_grouped['destination_1'] = users_grouped.groupby('user_id')['destination'].transform(lambda x: x.iloc[0] if len(x) > 0 else None)\n",
    "users_grouped['destination_2'] = users_grouped.groupby('user_id')['destination'].transform(lambda x: x.iloc[1] if len(x) > 1 else None)\n",
    "users_grouped['destination_3'] = users_grouped.groupby('user_id')['destination'].transform(lambda x: x.iloc[2] if len(x) > 2 else None)\n",
    "\n",
    "users_grouped['rating_1'] = users_grouped.groupby('user_id')['rating'].transform(lambda x: x.iloc[0] if len(x) > 0 else None)\n",
    "users_grouped['rating_2'] = users_grouped.groupby('user_id')['rating'].transform(lambda x: x.iloc[1] if len(x) > 1 else None)\n",
    "users_grouped['rating_3'] = users_grouped.groupby('user_id')['rating'].transform(lambda x: x.iloc[2] if len(x) > 2 else None)\n",
    "\n",
    "users_grouped = users_grouped.drop(columns=['destination', 'rating'])\n",
    "\n",
    "print(users_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d1188-319d-443e-9cbe-b3bd71b99d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final = users_grouped.drop_duplicates(subset='user_id')\n",
    "users_final = users_final[['user_id', 'destination_1', 'rating_1', 'destination_2', 'rating_2', 'destination_3', 'rating_3']]\n",
    "print(users_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc606e6-3972-454d-9223-0c5e605dbb6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final = users_final.sort_values(by='user_id').reset_index(drop=True)\n",
    "print(users_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04ac16-7154-43f2-99e0-537260823df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len([col for col in dynamicdata2.columns if col.startswith('cluster_') and col.endswith('_membership')])\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473baf1-d17a-4e49-b4ab-e33893532366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final2 =users_final\n",
    "\n",
    "for cluster_id in range(n_clusters):  \n",
    "    users_final2[f'rate_cluster_{cluster_id}'] = 0.0  \n",
    "\n",
    "for index, user_row in users_final.iterrows():\n",
    "    cluster_sums = {f'cluster_{i}_sum': 0.0 for i in range(n_clusters)} \n",
    "    cluster_counts = {f'cluster_{i}_count': 0 for i in range(n_clusters)} \n",
    "    \n",
    "    for dest_col, rate_col in [('destination_1', 'rating_1'), ('destination_2', 'rating_2'), ('destination_3', 'rating_3')]:\n",
    "        city = user_row[dest_col]\n",
    "        rating = user_row[rate_col]\n",
    "\n",
    "        city_data = dynamicdata2[dynamicdata2['city'] == city]\n",
    "        if not city_data.empty and pd.notna(rating):\n",
    "            for cluster_id in range(n_clusters):  \n",
    "                membership = city_data.iloc[0][f'cluster_{cluster_id}_membership']\n",
    "                cluster_sums[f'cluster_{cluster_id}_sum'] += membership * rating\n",
    "                cluster_counts[f'cluster_{cluster_id}_count'] += 1\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "        count = cluster_counts[f'cluster_{cluster_id}_count']\n",
    "        if count > 0:  \n",
    "            users_final2.at[index, f'rate_cluster_{cluster_id}'] = (\n",
    "                cluster_sums[f'cluster_{cluster_id}_sum'] / count\n",
    "            )\n",
    "\n",
    "print(users_final2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864c165-f598-4d36-b9e2-86349cbdd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_final2 = users_final2.drop(columns=['assigned_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e4d7a-f189-4a11-8f42-5b603049649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    \"Tehran\", \"Mashhad\", \"Isfahan\", \"Shiraz\", \"Tabriz\", \"Kerman\", \"Kish\", \"Qeshm\", \"Rasht\",\n",
    "    \"Ahvaz\", \"Yazd\", \"Urmia\", \"Kermanshah\", \"Sari\", \"Gorgan\"\n",
    "]\n",
    "for city in cities:\n",
    "    users_final2[city] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163761e-81d4-41cf-bfe0-37a44ce30e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final3 = users_final2\n",
    "for index, user_row in users_final3.iterrows():\n",
    "    for city in cities:\n",
    "        city_cluster = dynamicdata2.loc[dynamicdata2['city'] == city, 'cluster'].values[0]\n",
    "        \n",
    "        city_membership = dynamicdata2.loc[dynamicdata2['city'] == city, f'cluster_{city_cluster}_membership'].values[0]\n",
    "        \n",
    "        user_rate = user_row[f'rate_cluster_{city_cluster}']\n",
    "        \n",
    "        users_final3.at[index, city] = city_membership * user_rate\n",
    "print(users_final3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75cfc8-cce3-4656-b1a0-9f6082776c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_dynamic_rates = users_final3\n",
    "print(user_dynamic_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe752f-5153-4668-b550-7feddd3eef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dynamic_rates.to_excel('''r\"user dynamic rates Path\"''', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688cce8f-eab1-4c31-b3b2-49b1dfe1fbaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "staticdata2 =  staticdata\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def compute_distance_matrix(staticdata2):\n",
    "    city_names = staticdata2['City']\n",
    "    distances = np.zeros((len(city_names), len(city_names)))\n",
    "    for i, city1 in enumerate(city_names):\n",
    "        for j, city2 in enumerate(city_names):\n",
    "            if i != j:\n",
    "                lat1, lon1 = staticdata2.loc[i, ['Latitude', 'Longitude']]\n",
    "                lat2, lon2 = staticdata2.loc[j, ['Latitude', 'Longitude']]\n",
    "                distance = haversine(lat1, lon1, lat2, lon2)\n",
    "                distances[i, j] = distance\n",
    "    return distances\n",
    "\n",
    "def compute_feature_similarity(staticdata2):\n",
    "    features = ['Elevation', 'Area', 'Population']\n",
    "    city_features = staticdata2[features]\n",
    "    scaler = StandardScaler()\n",
    "    city_features_scaled = scaler.fit_transform(city_features)\n",
    "    return cosine_similarity(city_features_scaled)\n",
    "\n",
    "def combine_similarities(distance_matrix, feature_similarity_matrix, alpha=0.5):\n",
    "    max_distance = np.max(distance_matrix)\n",
    "    normalized_distance = 1 / (1 + distance_matrix / max_distance)  \n",
    "    \n",
    "    combined_similarity = alpha * feature_similarity_matrix + (1 - alpha) * normalized_distance\n",
    "    return combined_similarity\n",
    "\n",
    "distances = compute_distance_matrix(staticdata)\n",
    "feature_similarity = compute_feature_similarity(staticdata)\n",
    "combined_similarity = combine_similarities(distances, feature_similarity)\n",
    "\n",
    "combined_similarity_df = pd.DataFrame(combined_similarity, index=staticdata['City'], columns=staticdata['City'])\n",
    "\n",
    "print(combined_similarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cf9c6-a746-4403-a4d2-f1a9e37fb6e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final4 = users_grouped.drop_duplicates(subset='user_id')\n",
    "users_final4 = users_final4[['user_id', 'destination_1', 'rating_1', 'destination_2', 'rating_2', 'destination_3', 'rating_3']]\n",
    "\n",
    "users_final4 = users_final4.sort_values(by='user_id').reset_index(drop=True)\n",
    "\n",
    "cities = [\n",
    "    \"Tehran\", \"Mashhad\", \"Isfahan\", \"Shiraz\", \"Tabriz\", \"Kerman\", \"Kish\", \"Qeshm\", \"Rasht\",\n",
    "    \"Ahvaz\", \"Yazd\", \"Urmia\", \"Kermanshah\", \"Sari\", \"Gorgan\"\n",
    "]\n",
    "for city in cities:\n",
    "    users_final4[city] = 0\n",
    "print(users_final4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0894f-e399-45a6-a183-379c800dd6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, row in users_final4.iterrows():\n",
    "    for i in range(1, 4):\n",
    "        city_column = f'destination_{i}'\n",
    "        rating_column = f'rating_{i}'\n",
    "        \n",
    "        city = row[city_column]\n",
    "        rating = row[rating_column]\n",
    "        \n",
    "        if city in users_final4.columns:\n",
    "            users_final4.loc[idx, city] = rating\n",
    "\n",
    "print(users_final4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e4c72-659d-43c3-9052-bc3ccb0af560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final5 = users_final4.drop(columns = ['destination_1', 'destination_2', 'destination_3', 'rating_1', 'rating_2', 'rating_3'])\n",
    "print(users_final5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4d434-ca85-4d9f-9de6-ed7ef6b14963",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_final5.to_excel('''r\"users final5 Path\"''', index=False)\n",
    "combined_similarity_df.to_excel('''r\"combined similarity df Path\"''', index=False)\n",
    "filled_scores.to_excel(r'''\"filled scores Path\"''', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2872e-d14a-47f9-8bcd-cf2dfee7d33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_city_scores = users_final5\n",
    "user_scores = user_city_scores.drop(columns=['user_id'])\n",
    "\n",
    "def fill_missing_scores(user_scores, similarity_df):\n",
    "    for user_idx, user_row in user_scores.iterrows():\n",
    "        missing_items = user_row[user_row == 0].index\n",
    "        \n",
    "        for item in missing_items:\n",
    "            rated_items = user_row[user_row != 0].index\n",
    "            \n",
    "            weighted_scores = 0\n",
    "            similarity_sum = 0\n",
    "            for rated_item in rated_items:\n",
    "                similarity = similarity_df.loc[item, rated_item]\n",
    "                score = user_row[rated_item]\n",
    "                weighted_scores += similarity * score\n",
    "                similarity_sum += similarity\n",
    "            \n",
    "            if similarity_sum > 0:\n",
    "                user_scores.at[user_idx, item] = weighted_scores / similarity_sum\n",
    "            else:\n",
    "                user_scores.at[user_idx, item] = 0  \n",
    "\n",
    "    return user_scores\n",
    "\n",
    "filled_scores = fill_missing_scores(user_scores.copy(), combined_similarity_df)\n",
    "print(filled_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdfba40-f124-4c9b-83b2-c69ba5858de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_final6 = pd.read_excel('''r\"users_final5 Path\"''')\n",
    "print(users_final6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea627729-1855-4392-8a17-17fbefbacc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = users_final6.melt(id_vars='user_id', var_name='city', value_name='rating')\n",
    "df = df[df['rating'] > 0]  \n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'city', 'rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE on test set: {rmse}\")\n",
    "\n",
    "full_trainset = data.build_full_trainset()\n",
    "algo.fit(full_trainset)\n",
    "\n",
    "users = users_final6['user_id']\n",
    "cities = users_final6.columns[1:]\n",
    "\n",
    "final_predictions = users_final6.copy()\n",
    "\n",
    "for user in users:\n",
    "    for city in cities:\n",
    "        if final_predictions.loc[final_predictions['user_id'] == user, city].values[0] == 0:\n",
    "            pred = algo.predict(user, city).est  \n",
    "            final_predictions.loc[final_predictions['user_id'] == user, city] = pred\n",
    "\n",
    "print(\"Final predictions:\")\n",
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57595d-4cf4-4744-88a0-b132fc93b3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itembased_dynamic = pd.read_excel('''r\"users dynamic rates Path\"''')\n",
    "itembased_static = pd.read_excel(''''r\"users_static rates Path\"''')\n",
    "userbased = pd.read_excel('''r\"user based Path\"''')\n",
    "print(itembased_dynamic)\n",
    "print(itembased_static)\n",
    "print(userbased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f57e62-f675-46fa-b0e6-256706681f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_scores = itembased_dynamic.copy() \n",
    "final_scores.iloc[:, 1:] = (\n",
    "    0.50 * itembased_dynamic.iloc[:, 1:] +\n",
    "    0.25 * itembased_static.iloc[:, 1:] +\n",
    "    0.25 * userbased.iloc[:, 1:]\n",
    ")\n",
    "\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cc01a-172c-4226-8b1c-efed9e24aee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommended_cities = final_scores[['user_id']].copy()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    recommended_cities[f'Recommended City {i}'] = (\n",
    "        final_scores.iloc[:, 1:]  \n",
    "        .apply(lambda row: row.nlargest(i).idxmin(), axis=1) \n",
    "    )\n",
    "\n",
    "print(recommended_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f87a0-b762-4b46-8801-fb4cd37a1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores.to_excel('''r\"final_scores Path\"''', index=False)\n",
    "recommended_cities.to_excel('''r'recommended cities Path\"''', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dimred-env)",
   "language": "python",
   "name": "dimred-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
